--- 
title: "Final Project"
author: "Madeline Bean"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
biblio-style: apalike
link-citations: yes
github-repo: rstudio/bookdown-demo
description: "This is the final data science project for the Introduction to Data Science Course ESS 580A7."
---

# Introduction {-}

This bookdown website is comprised of all assignments completed in Introduction to Data Science Course ESS 580A7. I completed this class in my spring semester of 2022 while getting my Professional Science Master's in Ecosystem Sciences and Sustainability.

## View GitHub Code {-}

The code used to build this R Bookdown is hosted on GitHub.

[Final Project GitHub](https://github.com/maddiebean21/bookdown_final)

<!--chapter:end:index.Rmd-->

#Poudre River Interactive Graph

The Poudre River runs through northern Colorado, passing through Fort Collins, CO. In this assignment, we look at the the annual discharge of the river to determine annual patterns and severe weather events.

```{r poudresetup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dataRetrieval)
library(dygraphs)
library(xts)
```


## Methods

The Poudre River at Lincoln Bridge is:

  - Downstream of only a little bit of urban stormwater

  - Near Odell Brewing CO
  
  - Near an open space area and the Poudre River Trail
  
  - **Downstream of many agricultural diversions**


## Site Description

![](https://waterdata.usgs.gov/nwisweb/local/state/co/text/pics/06752260big.jpg)


## Data Acquisition and Plotting Tests

### Data Download


```{r Poudredatadownloader}

q <- readNWISdv(siteNumbers = '06752260',
                parameterCd = '00060',
                startDate = '2017-01-01',
                endDate = '2022-01-01') %>%
  rename(q = 'X_00060_00003')


```



### Static Data Plotter


```{r, poudreplotter, warning = FALSE, fig.width = 8, fig.height = 5}

ggplot(q, aes(x = Date, y = q)) + 
  geom_line() + 
  ylab('Q (cfs)') + 
  ggtitle('Discharge in the Poudre River, Fort Collins')

```


### Interactive Data Plotter


```{r poudreinteractiveplotter}

q_xts <- xts(q$q, order.by = q$Date)

#plotting
dygraph(q_xts) %>%
  dyAxis("y", label = "Discharge (cfs)") 
```


## Interactive Graph

```{r poudreassignment}
#creating an interactive graph
dygraph(q_xts) %>%
  dyOptions(drawPoints = TRUE, pointSize = 2)
  
```

## Information about the Poudre River

**The History of the Poudre River**

The Cache la Poudre River got its name from a group of French trappers that hid their gun powder on the banks of the river to lighten their wagons. Hence the translation of the name to be the *"hiding place of the powder."* Since the 1800's, the Poudre River has been a vital resource for the Northern Colorado community. From industrial to agricultural and to residential use, the water from the Poudre river is in great demand. 

**Poudre River Geomorphology**

The Poudre River starts high in the [Rocky Mountain National Park](https://www.nps.gov/romo/index.htm) peaks and flows north east through the [Roosevelt National Forest](https://www.fs.usda.gov/arp), slowly making its way through the city of Fort Collins. There are a lot of [recreational activities](https://www.visitftcollins.com/things-to-do/parks-open-spaces/cache-la-poudre-river/) that occur along the river, including hiking, biking, kayaking, and white water rafting. However, because of the multiple reservoirs that consume water from the Poudre, the once rapid, flowing river is now only a trickling stream in some areas, especially during the winter months. 


<!--chapter:end:01-hw-poudre.Rmd-->

# Hayman Fire Recovery 

The [Hayman Fire](https://en.wikipedia.org/wiki/Hayman_Fire) occurred on June 8th, 2002. This was the largest wildfire in Colorado's history until 2020, burning over 138,000 acres of land. In this assignment, we looked at how the fire affected vegetation growth in the area. 

```{r firesetup, warning=F,message=F}
library(tidyverse)
library(tidyr)
library(ggthemes)
library(lubridate)
library(ggpubr)

# Now that we have learned how to munge (manipulate) data
# and plot it, we will work on using these skills in new ways

knitr::opts_knit$set(root.dir='..')
```

## Reading in the Data

```{r firedataread, warning=F,message=F,show_col_types=FALSE}
####-----Reading in Data and Stacking it ----- ####
#Reading in files
files <- list.files('02-hw-hayman',full.names=T)


#Read in individual data files
ndmi <- read_csv('/Users/maddiebean21/Desktop/School/ESS580A7/bookdown_final/data/02-hw-hayman/hayman_ndmi.csv') %>% 
  rename(burned=2,unburned=3) %>%
  mutate(data='ndmi')

ndsi <- read_csv('/Users/maddiebean21/Desktop/School/ESS580A7/bookdown_final/data/02-hw-hayman/hayman_ndsi.csv') %>% 
  rename(burned=2,unburned=3) %>%
  mutate(data='ndsi')

ndvi <- read_csv('/Users/maddiebean21/Desktop/School/ESS580A7/bookdown_final/data/02-hw-hayman/hayman_ndvi.csv')%>% 
  rename(burned=2,unburned=3) %>%
  mutate(data='ndvi')

# Stack as a tidy dataset
full_long <- rbind(ndvi,ndmi,ndsi) %>%
  gather(key='site',value='value',-DateTime,-data) %>%
  filter(!is.na(value))


```


## NDVI and NDMI Correlation 

In order to find the correlation between NDVI and NDMI, we converted the full_long dataset into a wide dataset using the function "spread" and then made a plot of this function, grouped by unburned vs burned sites. We excluded winter months and focused on summer months because vegetation does not generally grow in the winter.

```{r firewidedata}
#changing data into wide
full_wide <- spread(data=full_long,key='data',value='value') %>%
  filter_if(is.numeric,all_vars(!is.na(.))) %>%
  mutate(month = month(DateTime),
         year = year(DateTime))

#filtering summer months
summer_only <- filter(full_wide,month %in% c(6,7,8,9))

#plotting summer months of variables
ggplot(summer_only,aes(x=ndmi,y=ndvi,color=site)) + 
  geom_point() + 
  theme_few() + 
  scale_color_few() + 
  theme(legend.position=c(0.8,0.8))

```

There is a strong, positive correlation between NDMI and NDVI. 

## Average NDSI and NDVI Correlation

In order to find the correlation between the average NDSI and NDVI, we used the data points for NDSI only during January - April (snow season) and only data points for NDVI during June - August (vegetation growth season). We found that there is a low positive correlation of 0.180 between snow coverage and vegetation. This means that the previous year's snow cover has little effect on the vegetation growth for the following summer and that this correlation could be from other factors in the environment. Looking at the graph, you can see a difference in correlation between NDVI and NDSI burned and un-burned sites.
 
```{r fireNDSINDVI, warning=F, message=F}
#variable ndsi months
var.snow_months <- c(1,2,3,4)

#variable ndvi months
var.growth_months <- c(6,7,8)

#mean NDSI per year
ndsi_avg <- full_wide[c("DateTime", "ndsi", "month", "year", "site")] %>%
  filter(month %in% var.snow_months) %>%
  group_by(site, year) %>%
  summarize(ndsi_avg=mean(ndsi))

#mean NDVI per year
ndvi_avg <- full_wide[c("DateTime", "ndvi", "month", "year", "site")] %>%
  filter(month %in% var.growth_months) %>%
  group_by(site, year) %>%
  summarize(ndvi_avg=mean(ndvi))

#combining NDVI and NDSI into one dataset
combined <- inner_join(ndvi_avg, ndsi_avg)

#correlation
cor(combined$ndvi_avg, combined$ndsi_avg)

ggplot(combined, aes(x=ndsi_avg, y=ndvi_avg, color=site)) +
  geom_point() + 
  theme_few() + 
  scale_color_few() + 
  theme(legend.position=c(0.8,0.8))
  
```
 
## Snow Effect Differences

We then looked at the difference of snow effect from the previous correlation between pre- and post-burn and burned and unburned.

```{r firesnoweffect, warning=F, message=F}
#snow effect pre-burn
preburn <- c(1984:2001)

#snow effect post-burn
postburn <- c(2003:2019)

#snow effect average for preburn
ndsi_preburn_avg <- full_wide[c("DateTime", "ndsi", "month", "year", "site")] %>%
  filter(month %in% var.snow_months) %>%
  filter(year %in% preburn) %>%
  group_by(site, year) %>%
  summarize(ndsi_preburn_avg=mean(ndsi))

#vegetation effect average for preburn
ndvi_preburn_avg <- full_wide[c("DateTime", "ndvi", "month", "year", "site")] %>%
  filter(month %in% var.growth_months) %>%
  filter(year %in% preburn) %>%
  group_by(site, year) %>%
  summarize(ndvi_preburn_avg=mean(ndvi))

#combing preburn ndsi and ndvi into one data set
combine_preburn <- inner_join(ndsi_preburn_avg, ndvi_preburn_avg)

#correlation for preburn
cor(combine_preburn$ndsi_preburn_avg, combine_preburn$ndvi_preburn_avg)

#snow effect average for postburn
ndsi_postburn_avg <- full_wide[c("DateTime", "ndsi", "month", "year", "site")] %>%
  filter(month %in% var.snow_months) %>%
  filter(year %in% postburn) %>%
  group_by(site, year) %>%
  summarize(ndsi_postburn_avg=mean(ndsi))

#vegetation effect average for postburn
ndvi_postburn_avg <- full_wide[c("DateTime", "ndvi", "month", "year", "site")] %>%
  filter(month %in% var.growth_months) %>%
  filter(year %in% postburn) %>%
  group_by(site, year) %>%
  summarize(ndvi_postburn_avg=mean(ndvi))

#combing postburn ndsi and ndvi into one data set
combine_postburn <- inner_join(ndsi_postburn_avg, ndvi_postburn_avg)

#correlation for postburn
cor(combine_postburn$ndsi_postburn_avg, combine_postburn$ndvi_postburn_avg)

#snow effect average for burned 
ndsi_burned_avg <- full_wide[c("DateTime", "ndsi", "month", "year", "site")] %>%
  filter(month %in% var.snow_months) %>%
  filter(site %in% "burned") %>%
  group_by(site, year) %>%
  summarize(ndsi_burned_avg=mean(ndsi))
#snow effect average for unburned
ndsi_unburned_avg <- full_wide[c("DateTime", "ndsi", "month", "year", "site")] %>%
  filter(month %in% var.snow_months) %>%
  filter(site %in% "unburned") %>%
  group_by(site, year) %>%
  summarize(ndsi_unburned_avg=mean(ndsi))

#vegetation effect average for burned 
ndvi_burned_avg <- full_wide[c("DateTime", "ndvi", "month", "year", "site")] %>%
  filter(month %in% var.growth_months) %>%
  filter(site %in% "burned") %>%
  group_by(site, year) %>%
  summarize(ndvi_burned_avg=mean(ndvi))

#vegetation effect average for unburned
ndvi_unburned_avg <- full_wide[c("DateTime", "ndvi", "month", "year", "site")] %>%
  filter(month %in% var.growth_months) %>%
  filter(site %in% "unburned") %>%
  group_by(site, year) %>%
  summarize(ndvi_unburned_avg=mean(ndvi))

#combining data for burned
combined_burned <- inner_join(ndvi_burned_avg, ndsi_burned_avg)

#combining data for unburned
combined_unburned <- inner_join(ndvi_unburned_avg, ndsi_unburned_avg)

#correlation for burned data
cor(combined_burned$ndvi_burned_avg, combined_burned$ndsi_burned_avg)

#correlation for unburned data
cor(combined_unburned$ndvi_unburned_avg, combined_unburned$ndsi_unburned_avg)

#graphing the data 
Preburngraph <- ggplot(combine_preburn, aes(x=ndsi_preburn_avg, y=ndvi_preburn_avg)) +
  geom_point() + 
  theme_few() + 
  scale_color_few() +
  labs(x="Pre-burn NDSI Average", y="Pre-burn NDVI Average")

Postburngraph <- ggplot(combine_postburn, aes(x=ndsi_postburn_avg, y=ndvi_postburn_avg)) +
  geom_point() + 
  theme_few() + 
  scale_color_few()+
  labs(x="Post-burn NDSI Average", y = "Post-burn NDVI Average")

Burnedgraph <- ggplot(combined_burned, aes(x=ndsi_burned_avg, y=ndvi_burned_avg)) +
  geom_point() + 
  theme_few() + 
  scale_color_few()+
  labs(x="NDSI Burned Average", y="NDVI Burned Average")

Unburnedgraph <- ggplot(combined_unburned, aes(x=ndsi_unburned_avg, y=ndvi_unburned_avg))+
  geom_point() + 
  theme_few() + 
  scale_color_few()+
  labs(x= "Average NDSI Unburned", y="Average NDVI Unburned")

#Plotting the data in one frame
Plot <- ggarrange(Preburngraph, Postburngraph, Burnedgraph, Unburnedgraph,
                 labels = c("Pre-burned", "Post-burned", "Burned", "Unburned"),
                 ncol = 2, nrow = 2)

Plot
                  
```

For pre-burn snow effect, the correlation is 0.091.

For post-burn snow effect, the correlation is 0.244.

For un-burned snow effect, the correlation is -0.031

For burned snow effect, the correlation is 0.087.

The snow effect from question 2 is a more generalized correlation. While all of these variables have a weak correlation, this question isolates the different variables in the data to help determine the relationship between snow coverage and vegetation growth. The post-burn condition has the strongest correlation between the previous year's snow coverage and the vegetation growth for the following year. The weakest correlation between snow coverage and vegetation growth was for the un-burned condition. This is interesting because this could potentially mean that the Hayman Fire has pushed the vegetation growth to rely more on snow coverage to get their nutrients. This is still a weak correlation, so more research will need to be conducted to determine if this is true or not; there are many other variables in the environment that could have caused this correlation.
 

## Average Greenest Month

Here, we looked at which month was the greenest, on average. We discovered that August was the greenest month.

```{r warning=F, message=F}
#creating an object for the average vegetation for each month
ndvigreenest <- full_wide[c("DateTime", "ndvi", "month", "year", "site")] %>%
  group_by(month) %>%
  summarize(ndvi=mean(ndvi))

#Plotting the average vegetation for each month
ggplot(ndvigreenest, aes(x=month, y=ndvi)) +
  geom_bar(stat="identity", fill="#009E73") +
  theme_minimal()
  
```


## Average Snowiest Month

Next, we looked at which month was the snowiest on average. January was the snowiest month.

```{r warning=F, message=F}
#creating snow object
ndsisnowiest <- full_wide[c("DateTime", "ndsi", "month", "year", "site")] %>%
  group_by(month) %>%
  summarize(ndsi=mean(ndsi))

#plotting the snow for each month
ggplot(ndsisnowiest, aes(x=month, y=ndsi)) +
  geom_bar(stat="identity", fill="#56B4E9") +
  theme_minimal() 
```

<!--chapter:end:02-hw-hayman-fire.Rmd-->

# Snow Data Example

In this assignment, I explored web scraping, different functions and iterations by using a data set from the Center for Snow and Avalanche Studies  [Website](https://snowstudies.org/archived-data/) and read a table in. This table contains links to data I want and to programatically download for three sites. I don't know much about these sites, but they contain incredibly rich snow, temperature, and precip data. 

```{r setup, include=FALSE}
library(rvest)
library(tidyverse)
library(lubridate)
library(readxl)

```

## Reading an html 

### Extract CSV links from webpage

```{r snowfunctionsetup}

site_url <- 'https://snowstudies.org/archived-data/'

#Read the web url
webpage <- read_html(site_url)

#See if we can extract tables and get the data that way
tables <- webpage %>%
  html_nodes('table') %>%
  magrittr::extract2(3) %>%
  html_table(fill = TRUE)
#That didn't work, so let's try a different approach

#Extract only weblinks and then the URLs!
links <- webpage %>%
  html_nodes('a') %>%
  .[grepl('24hr',.)] %>%
  html_attr('href')

```

## Data Download

### Download data in a for loop

```{r snowdownloadingdata}

#Grab only the name of the file by splitting out on forward slashes
splits <- str_split_fixed(links,'/',8)

#Keep only the 8th column
dataset <- splits[,8] 

#generate a file list for where the data goes
file_names <- paste0('data',dataset)

for(i in 1:3){
  download.file(links[i],destfile=file_names[i])
}

downloaded <- file.exists(file_names)

evaluate <- !all(downloaded)

```


### Download data in a map

```{r snowmapping}

#Map version of the same for loop (downloading 3 files)
if(evaluate == T){
  map2(links[1:3],file_names[1:3],download.file)
}else{print('data already downloaded')}

```

## Data read-in 

### Read in just the snow data as a loop

```{r snowreadindata}
#Pattern matching to only keep certain files
snow_files <- file_names %>%
  .[!grepl('SG_24',.)] %>%
  .[!grepl('PTSP',.)]

empty_data <- list()

snow_data <- for(i in 1:length(snow_files)){
  empty_data[[i]] <- read_csv(snow_files[i]) %>%
    select(Year,DOY,Sno_Height_M)
  }

snow_data_full <- do.call('rbind',empty_data)

summary(snow_data_full)
```


### Read in the data as a map function

```{r snowmapfunction}
#making the data as a map function
our_snow_reader <- function(file){
  name = str_split_fixed(file,'/',2)[,2] %>%
    gsub('_24hr.csv','',.)
  df <- read_csv(file) %>%
    select(Year,DOY,Sno_Height_M) %>%
    mutate(site = name)
}
#creating an object with the functions
snow_data_full <- map_dfr(snow_files,our_snow_reader)

summary(snow_data_full)
```


### Plot snow data

```{r snowplotting}

#making an object for the yearly snow data points
snow_yearly <- snow_data_full %>%
  group_by(Year,site) %>%
  summarize(mean_height = mean(Sno_Height_M,na.rm=T))

#plotting the yearly snow data
ggplot(snow_yearly,aes(x=Year,y=mean_height,color=site)) + 
  geom_point() +
  ggthemes::theme_few() + 
  ggthemes::scale_color_few()+
  labs(x="Mean Height", y="Year", title="Yearly Snow Data")
```

## Extracting the meteorological data URLs

I used the `rvest` package to get the URLs for the `SASP forcing` and `SBSP_forcing` meteorological datasets. 

```{r snowextracting}
#creating values for the meteorological data URLs
links_hw <- webpage %>%
  html_nodes('a') %>%
  .[grepl('forcing',.)] %>%
  html_attr('href')
links_hw
```


## Download the meteorological data. 

Next, I used the `download_file` and `str_split_fixed` commands, along with a for loop, to download the data and saved it in our data folder.

```{r snowdownloader}

# grab only the name of the file by splitting out on forward slashes
splits_hw <- str_split_fixed(links_hw, '/', 8)

forcingdataset <- splits_hw[,8] %>% 
  gsub('.txt','',.)

file_names_hw <- paste0('data/', forcingdataset)

# creating a for loop
for(i in 1:length(file_names_hw)){
  download.file(links_hw[i], destfile=file_names_hw[i])
}

file_names_hw

```

## Custom function writing

I wrote a custom function in order to read in the data and append a site column to the data. 

```{r snowfunction}

# this code grabs the variable names from the metadata pdf file
library(pdftools)
q3_headers <- pdf_text('https://snowstudies.org/wp-content/uploads/2022/02/Serially-Complete-Metadata-text08.pdf') %>%
  readr::read_lines(.) %>%
  trimws(.) %>%
  str_split_fixed(.,'\\.',2) %>%
  .[,2] %>%
  .[1:26] %>%
  str_trim(side = "left")
q3_headers

#creating a function
q3_reader <- function(file){
  name = str_split_fixed(file, '/', 2)[,2] 
  name2 = str_split_fixed(file, '_', 4)[,2]
  q3test = read.delim(file, header = FALSE, sep ="", col.names = q3_headers, skip = 4) %>%
  select(1:14) %>%
  mutate(site=name2)
}

```

## Summary of meteorlogical files

 I used the `map` function to read in both meteorological files and then displayed a summary of my tibble.

```{r snowmapfunctions}

#reading in the forcing data 
forcing_data_full <- map_dfr(file_names_hw, q3_reader)

summary(forcing_data_full)
```


##Average yearly temperature 

I made a line plot of mean temp by year by site (using the `air temp [K]` variable). What is suspicious about this data is temperature variation at the beginning of the graph, especially since the temperature is in Kelvin. This eludes that temperature was most likely not collected in the earlier years. 

```{r snowlineplot, warning = FALSE}
#creating an object to plot, grabbing the mean temperature by year by site
q5_yearly <- forcing_data_full %>%
  group_by(year,site) %>%
  summarize(mean_temp_k = mean(air.temp..K.,na.rm=T))
 
#plotting the mean temperature by year by site
ggplot(q5_yearly) + 
  geom_line(aes(x=year,y=mean_temp_k,color=site)) + 
  ggthemes::theme_few() + 
  ggthemes::scale_color_few()
```
What is suspicious about this data is temperature variation at the beginning of the graph, especially since the temperature is in Kelvin. This eludes that temperature was most likely not collected in the earlier years.

## Monthy average temperature plot

Here, i wrote a function in order to make line plots of monthly average temperature at each site for a given year. I used a for loop to make these plots for 2005 to 2010. Both sites follow the same trend for each month, however, the SBSP site is never warmer than SASP site. There are times where are almost the same temperature, but SBSP never exceeds SASP.

```{r snowfunctionplot}

#creating a function for the monthly average temperature
forcingmonthyear <- function(forcing_data_full, year){
  monthlytemp<-forcing_data_full %>%
    group_by(month,year,site) %>%
    summarize(monthly_air_temp = mean(air.temp..K.,na.rm=T)) %>%
    filter(yr == year)
  
  #plotting the function
  plots <- ggplot(monthlytemp, aes(x = month, y = monthly_air_temp, color = site)) +
    geom_line(size=2)+
    facet_wrap(~year)
    labs(title= monthlytemp$year,
         x = "Month",
         y = "Temperature (K)")
  
  print(plots)
}

years <- c(2005,2006,2007,2008,2009,2010)
  
#creating a for loop
for (yr in years) {
  forcingmonthyear(forcing_data_full, year)
}
  
```

## Average daily precipitation

For this graph, I grouped the data by day by site to get the daily temperature. 

```{r snowbonus}

# making an object for daily temperature
dailytemp<-forcing_data_full %>%
    group_by(day,site) %>%
    summarize(daily_air_temp = mean(air.temp..K.,na.rm=T))

#plotting bonus
ggplot(dailytemp, aes(x=day, y=daily_air_temp, color=site))+
  geom_line()+
  labs(x='Day of the Month', y='Daily Air Temperature', title = "Daily Temperature")
```



<!--chapter:end:03-hw-snow-functions.Rmd-->

